In [1]: import pandas as pd # for data manipulation and analysis
import numpy as np
import requests
import seaborn as sns # for data visualization
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.model_selection import train_test_split # for machine learning
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
# Always show DataFrame as plain text in Jupyter
pd.set_option("display.notebook_repr_html", False)
In [2]: # Option 2: Force column 2 to string
df = pd.read_csv("MTA_Subway_Hourly_Ridership__Beginning_2025_20250923.csv", nr
In [3]: df

Out[3]:
0
1
2
3
4
...
01/07/2025 06:00:00 PM
transit_timestamp transit_mode station_complex_id \
subway
339
01/07/2025 06:00:00 PM
01/07/2025 06:00:00 PM
01/07/2025 06:00:00 PM
01/07/2025 06:00:00 PM
...
6999995 03/23/2025 12:00:00 PM
6999996 03/23/2025 12:00:00 PM
6999997 03/23/2025 12:00:00 PM
6999998 03/23/2025 12:00:00 PM
6999999 03/23/2025 12:00:00 PM
subway
subway
subway
subway
...
subway
subway
subway
subway
subway
340
340
340
343
...
636
64
64
65
65
0
1
2
3
4
...
station_complex borough payment_method \
Bergen St (2,3) Brooklyn
metrocard
Grand Army Plaza (2,3) Brooklyn
Grand Army Plaza (2,3) Brooklyn
Grand Army Plaza (2,3) Brooklyn
Nostrand Av (3) Brooklyn
...
...
6999995 Jay St-MetroTech (A,C,F,R) Brooklyn
71 St (D) Brooklyn
6999996
6999997
6999998
6999999
0
1
2
3
4
...
6999995
6999996
6999997
6999998
6999999
0
1
2
3
4
...
71 St (D) Brooklyn
79 St (D) Brooklyn
79 St (D) Brooklyn
metrocard
metrocard
metrocard
metrocard
...
metrocard
metrocard
omny
metrocard
omny
fare_class_category ridership transfers latitude \
Metrocard - Unlimited 7-Day
Metrocard - Fair Fare
Metrocard - Seniors & Disability
Metrocard - Unlimited 30-Day
Metrocard - Full Fare
...
Metrocard - Unlimited 30-Day
Metrocard - Unlimited 7-Day
OMNY - Students
Metrocard - Unlimited 30-Day
OMNY - Students
longitude
-73.97510
Georeference
POINT (-73.9751 40.68083)
-73.97105 POINT (-73.97105 40.675236)
-73.97105 POINT (-73.97105 40.675236)
-73.97105 POINT (-73.97105 40.675236)
-73.95046 POINT (-73.95046 40.669846)
...
...
6999995 -73.98594 POINT (-73.98594 40.692337)
6999996 -73.99886 POINT (-73.99886 40.61959)
6999997 -73.99886 POINT (-73.99886 40.61959)
6999998 -74.00061 POINT (-74.00061 40.613503)
6999999 -74.00061 POINT (-74.00061 40.613503)
[7000000 rows x 12 columns]
In [4]: df['transit_timestamp'] = pd.to_datetime(df['transit_timestamp'])
12
13
23
38
10
...
33
12
27
14
27
0 40.680830
2 40.675236
3 40.675236
0 40.675236
0 40.669846
...
...
0 40.692337
0 40.619590
0 40.619590
0 40.613503
0 40.613503

C:\Users\Bagdo\AppData\Local\Temp\ipykernel_1420\3131658029.py:1: UserWarning:
Could not infer format, so each element will be parsed individually, falling b
ack to `dateutil`. To ensure parsing is consistent and as-expected, please spe
cify a format.
df['transit_timestamp'] = pd.to_datetime(df['transit_timestamp'])
In [5]: df.shape
Out[5]:
In [6]: df.isnull().sum()
Out[6]:
(7000000, 12)
transit_timestamp
transit_mode
station_complex_id
station_complex
borough
payment_method
fare_class_category
ridership
transfers
latitude
longitude
Georeference
dtype: int64
0
0
0
0
0
0
0
0
0
0
0
0
In [7]: df['station_complex'] = df['station_complex'].str.replace(r'\(.*\)', '', regex=
In [8]: df['month'] = df['transit_timestamp'].dt.month
df['day'] = df['transit_timestamp'].dt.day
df['hour'] = df['transit_timestamp'].dt.hour
df['ridership'] = df['ridership']
df['day_of_week'] = df['transit_timestamp'].dt.dayofweek # 0=Mon, 6=Sun
df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
In [9]: df = df.groupby(['month', 'day', 'hour','borough','is_weekend','day_of_week'])
In [10]: df = pd.get_dummies(df, columns=['borough'], prefix='borough')
In [ ]:
In [11]: X = df[['month', 'day', 'hour','borough_Queens','borough_Manhattan','borough_St
'is_weekend']]
y = df['ridership']
# Split the data into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random
In [12]: # Split the data into features and labels
labels = np.array(df['ridership'])
features = df.drop('ridership', axis=1)
feature_list = list(features.columns)
features = np.array(features)
In [13]: df["borough_Queens"] = df["borough_Queens"].astype(int)
df["borough_Manhattan"] = df["borough_Manhattan"].astype(int)
df["borough_Staten Island"] = df["borough_Staten Island"].astype(int)

df["borough_Bronx"] = df["borough_Bronx"].astype(int)
df["borough_Brooklyn"] = df["borough_Brooklyn"].astype(int)
df["is_weekend"] = df["is_weekend"].astype(int)
In [14]: features
Out[14]:
array([[1, 4, 0, ..., False, False, False],
[1, 4, 0, ..., False, False, False],
[1, 4, 0, ..., True, False, False],
...,
[7, 25, 21, ..., True, False, False],
[7, 25, 22, ..., True, False, False],
[7, 25, 23, ..., True, False, False]], dtype=object)
In [15]: train_features, test_features, train_labels, test_labels = train_test_split(
features, labels, test_size=0.25, random_state=38
)
In [ ]:
In [ ]: from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
# Define the model
rf = RandomForestRegressor(random_state=38)
# Define the parameter grid
param_grid = {
'n_estimators': [100, 200, 400],
'max_depth': [None, 10, 20, 30],
'min_samples_split': [2, 5, 10],
'min_samples_leaf': [1, 2, 4],
'max_features': ['sqrt', 'log2']
}
# Set up GridSearchCV
grid_search = GridSearchCV(
estimator=rf,
param_grid=param_grid,
cv=3,
# 3-fold cross validation
n_jobs=-1,
verbose=2,
scoring='r2'
)
# Fit grid search to training data
grid_search.fit(train_features, train_labels)
# Best hyperparameters
print("✅ Best Parameters:", grid_search.best_params_)
print("✅ Best R² Score:", grid_search.best_score_)
In [21]: rf_best = RandomForestRegressor(
max_depth=20,
max_features='sqrt',
min_samples_leaf=1,
min_samples_split=2,
# use all CPU cores
# optimize for R²

n_estimators=400,
random_state=38
)
rf_best.fit(train_features, train_labels)
Out[21]: ▾
RandomForestRegressor
RandomForestRegressor(max_depth=20, max_features='sqrt', n_estimators=
400,
random_state=38)
In [22]: from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import numpy as np
predictions = rf_best.predict(test_features)
mae = mean_absolute_error(test_labels, predictions)
r2 = r2_score(test_labels, predictions)
rmse = np.sqrt(mean_squared_error(test_labels, predictions))
smape = 100 * np.mean(
2 * np.abs(predictions - test_labels) / (np.abs(test_labels) + np.abs(predi
)
print("MAE:", round(mae, 2))
print("RMSE:", round(rmse, 2))
print("R²:", round(r2, 3))
print("SMAPE:", round(smape, 2), "%")
MAE: 2903.57
RMSE: 7940.28
R²: 0.963
SMAPE: 33.63 %
In [57]: import joblib
# Save the model
joblib.dump(rf_best, "rf_best_model.pkl")
print("Model saved successfully.")
Model saved successfully.
In [23]: plt.figure(figsize=(10, 6))
plt.scatter(test_labels, predictions, alpha=0.7)
plt.plot([min(test_labels), max(test_labels)], [min(test_labels), max(test_labe
plt.xlabel('Actual Ridership')
plt.ylabel('Predicted Ridership')
plt.title('Random Forest Regressor: Actual vs. Predicted Ridership')
plt.show()

In [24]: # Train the model on training data
rf_best.fit(train_features, train_labels)
# Get feature importances
feature_importances = rf_best.feature_importances_
# Associate feature importances with feature names
feature_importance_list = list(zip(feature_list, feature_importances))
# Print the top N most important features and their importances
for feature, importance in feature_importance_list:
print(f"{feature}: {importance}")
# Create a bar plot to visualize feature importances
plt.figure(figsize=(10, 6))
plt.bar(range(len(feature_importances)), feature_importances)
plt.xticks(range(len(feature_importances)), [feature[0] for feature in feature_
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importances')
plt.show()
month: 0.24629933840117232
day: 0.058390589192784656
hour: 0.3794652151485105
is_weekend: 0.02004113932981861
day_of_week: 0.036758673830466354
borough_Bronx: 0.024615045293072985
borough_Brooklyn: 0.024401961573944538
borough_Manhattan: 0.14534189969349828
borough_Queens: 0.017730882875768083
borough_Staten Island: 0.0469552546609638

In [39]: df

Out[39]:
0
1
2
3
4
...
12639
12640
12641
12642
12643
0
1
2
3
4
...
12639
12640
12641
12642
12643
0
1
2
3
4
...
12639
12640
12641
12642
12643
[12644 rows x 11 columns]
In [40]: def predict_and_show_ridership(month, day, hour, borough, day_of_week=None, is_
# Borough list in same order as columns
boroughs = ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island']
borough_encoding = [1 if b == borough else 0 for b in boroughs]
# Calculate day_of_week if not provided
if day_of_week is None:
try:
date = pd.Timestamp(year=2025, month=month, day=day)
day_of_week = date.dayofweek
except Exception as e:
print("Invalid date:", e)
return
# Calculate is_weekend if not provided
if is_weekend is None:
is_weekend = int(day_of_week in [5, 6])
# Build input in exact column order
month day hour is_weekend day_of_week ridership borough_Bronx \
1163
1
1
1
1
1
4
4
4
4
4
0
0
0
0
0
... ... ...
7 25
19
7 25
7 25
7 25
7 25
20
21
22
23
1
1
1
1
1
...
0
0
0
0
0
5
5
5
5
5
...
4
4
4
4
4
5272
24702
2823
63
...
509
500
421
299
149
borough_Brooklyn borough_Manhattan borough_Queens \
0
0
1
0
0
0
...
0
0
0
0
0
borough_Staten Island
0
0
0
0
1
...
0
0
0
0
0
0
1
0
0
...
1
1
1
1
1
0
0
0
1
0
...
0
0
0
0
0
1
0
0
0
0
...
0
0
0
0
0

input_data = [[month, day, hour, is_weekend, day_of_week] + borough_encodin
# Predict
predicted_ridership = rf_best.predict(input_data)
# Find actual ridership if exists
actual_ridership = df[
(df['month'] == month) &
(df['day'] == day) &
(df['hour'] == hour) &
(df[f'borough_{borough}'] == 1)
]['ridership']
actual_ridership = actual_ridership.values[0] if len(actual_ridership) > 0
print(f"Input: Month={month}, Day={day}, Hour={hour}, Borough={borough}, Da
print(f"Predicted Ridership: {round(predicted_ridership[0], 2)}")
print(f"Actual Ridership: {actual_ridership}")
In [56]: predict_and_show_ridership(month=2, day=2, hour=1, borough="Brooklyn", day_of_w
Input: Month=2, Day=2, Hour=1, Borough=Brooklyn, Day_of_week=2, Is_weekend=0
Predicted Ridership: 1594.06
Actual Ridership: 3596
In [ ]:
In [ ]:

